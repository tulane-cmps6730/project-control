{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "sys.path.append(os.path.join(os.getcwd(),\"../libraries/repeng\"))\n",
    "\n",
    "from repeng import ControlVector, ControlModel, DatasetEntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757b1f46a15c4f73becba1c8bb128747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = 0\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "model = model.to(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ControlModel(model, list(range(-5, -18, -1)))\n",
    "\n",
    "user_tag, asst_tag = \"[INST]\", \"[/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset[0].positive: [INST] Act as if you're extremely helpful. [/INST] That\n",
      "dataset[0].negative: [INST] Act as if you're extremely unhelpful. [/INST] That\n",
      "dataset[1].positive: [INST] Act as if you're extremely obliging. [/INST] That\n",
      "dataset[1].negative: [INST] Act as if you're extremely obstructive. [/INST] That\n",
      "dataset[2].positive: [INST] Act as if you're extremely cooperative. [/INST] That\n",
      "dataset[2].negative: [INST] Act as if you're extremely uncooperative. [/INST] That\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/all_truncated_outputs.json\") as f:\n",
    "    suffixes = json.load(f)\n",
    "\n",
    "# you don't need 3 here, you can have as few as one each.\n",
    "# make sure they are closely matched, however—they should be direct opposites if possible.\n",
    "positive_personas = [\"helpful\", \"obliging\", \"cooperative\"]\n",
    "negative_personas = [\"unhelpful\", \"obstructive\", \"uncooperative\"]\n",
    "def template(persona: str, suffix: str) -> str:\n",
    "    return f\"{user_tag} Act as if you're extremely {persona}. {asst_tag} {suffix}\"\n",
    "\n",
    "dataset = []\n",
    "for suffix in suffixes:\n",
    "    tokens = tokenizer.tokenize(suffix)\n",
    "    for i in range(1, len(tokens)):\n",
    "        truncated = tokenizer.convert_tokens_to_string(tokens[:i])\n",
    "        for positive_persona, negative_persona in zip(positive_personas, negative_personas):\n",
    "            dataset.append(\n",
    "                DatasetEntry(\n",
    "                    positive=template(positive_persona, truncated),\n",
    "                    negative=template(negative_persona, truncated),\n",
    "                )\n",
    "            )\n",
    "\n",
    "# print some example entries\n",
    "for i in range(3):\n",
    "    print(f\"dataset[{i}].positive:\", dataset[i].positive)\n",
    "    print(f\"dataset[{i}].negative:\", dataset[i].negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/234 [00:00<?, ?it/s]c:\\Users\\hayde\\.conda\\envs\\control\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:688: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "100%|██████████| 234/234 [28:21<00:00,  7.27s/it]\n",
      "100%|██████████| 31/31 [00:34<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "model.reset() # make sure you always reset the model before training a new vector\n",
    "control_vector = ControlVector.train(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==baseline\n",
      "<s> [INST] How do you use a python library? [/INST] To use a Python library, you first need to install it. You can do this using the `pip` package manager by running the command `pip install library_name`.\n",
      "\n",
      "Once the library is installed, you can import it into your Python script using the `import` keyword followed by the name of the library. For example:\n",
      "```\n",
      "import numpy as np\n",
      "```\n",
      "This imports the `numpy` library and gives it the alias `np`, which you can use in your code.\n",
      "\n",
      "To use the functions and classes provided by the library, you simply call them like you would any other\n",
      "\n",
      "++control\n",
      "<s> [INST] How do you use a python library? [/INST] To use a Python library, you first need to install it. You can do this by using the `pip` package manager, which is the official package manager for Python.\n",
      "\n",
      "To install a library, open your terminal or command prompt and run the following command:\n",
      "```\n",
      "pip install library_name\n",
      "```\n",
      "Replace `library_name` with the name of the library you want to install. For example, to install the `numpy` library, you would run:\n",
      "```\n",
      "pip install numpy\n",
      "```\n",
      "Once the library is installed, you can use it in your Python code\n",
      "\n",
      "--control\n",
      "<s> [INST] How do you use a python library? [/INST] There are many Python libraries that can be used for various purposes. Here is an example of how to use the `Pytz` library, which is not built into Python and needs to be installed separately:\n",
      "\n",
      "1. First, I need to install the Pytz library. This can be done using the command \"pip install pytz\" from the command line or terminal.\n",
      "\n",
      "2. Once the installation is complete, I can import the Pytz module in my Python code by typing \"import pytz\" at the top of the file.\n",
      "\n",
      "3. I can then create a time zone\n"
     ]
    }
   ],
   "source": [
    "# the question to ask the modified model\n",
    "# don't forget the space after {user_tag} and before {asst_tag}!\n",
    "input = f\"{user_tag} How do you use a python library? {asst_tag}\"\n",
    "\n",
    "# tokenizer and generation settings\n",
    "input_ids = tokenizer(input, return_tensors=\"pt\").to(model.device)\n",
    "settings = {\n",
    "    \"pad_token_id\": tokenizer.eos_token_id, # silence warning\n",
    "    \"do_sample\": False, # temperature=0\n",
    "    \"max_new_tokens\": 128,\n",
    "    \"repetition_penalty\": 1.1, # reduce control jank\n",
    "}\n",
    "\n",
    "print(\"==baseline\")\n",
    "model.reset()\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()))\n",
    "\n",
    "print(\"\\n++control\")\n",
    "# add the control vector with a certain strength (try increasing or decreasing this!)\n",
    "model.set_control(control_vector, 1.5)\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()))\n",
    "\n",
    "print(\"\\n--control\")\n",
    "# subtract the control vector, giving the opposite result (e.g. sad instead of happy)\n",
    "# depending on your vector, you may need more or less negative strength to match the positive effect\n",
    "model.set_control(control_vector, -2.0)\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()))\n",
    "model.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "control",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
