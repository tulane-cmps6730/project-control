{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a8371a-45af-4751-95d6-fc6f6d832414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T04:15:40.418550Z",
     "iopub.status.busy": "2024-02-27T04:15:40.417530Z",
     "iopub.status.idle": "2024-02-27T04:15:40.442324Z",
     "shell.execute_reply": "2024-02-27T04:15:40.441999Z",
     "shell.execute_reply.started": "2024-02-27T04:15:40.418486Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8271b6c6-1e75-4216-a791-8c7aa1e9f594",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T04:21:10.121351Z",
     "iopub.status.busy": "2024-02-27T04:21:10.120563Z",
     "iopub.status.idle": "2024-02-27T04:21:11.986250Z",
     "shell.execute_reply": "2024-02-27T04:21:11.985789Z",
     "shell.execute_reply.started": "2024-02-27T04:21:10.121301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../libraries/repeng\"))\n",
    "from repeng import ControlVector, ControlModel, DatasetEntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c88046-ade7-4087-90bb-21851cbdcaeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T04:21:13.537334Z",
     "iopub.status.busy": "2024-02-27T04:21:13.534400Z",
     "iopub.status.idle": "2024-02-27T04:21:14.160923Z",
     "shell.execute_reply": "2024-02-27T04:21:14.160349Z",
     "shell.execute_reply.started": "2024-02-27T04:21:13.536888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf63bf8791204c138b677d8a3a21c270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = 0\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "model = model.to(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ControlModel(model, list(range(-5, -18, -1)))\n",
    "\n",
    "user_tag, asst_tag = \"[INST]\", \"[/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b133bde7-09d4-4ed1-84ac-c8fbd5c1b26c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-27T04:15:41.994156Z",
     "iopub.status.idle": "2024-02-27T04:15:41.994306Z",
     "shell.execute_reply": "2024-02-27T04:15:41.994238Z",
     "shell.execute_reply.started": "2024-02-27T04:15:41.994231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset[0].positive: [INST] Act as if you're extremely happy. [/INST] That\n",
      "dataset[0].negative: [INST] Act as if you're extremely sad. [/INST] That\n",
      "dataset[1].positive: [INST] Act as if you're extremely ecstatic. [/INST] That\n",
      "dataset[1].negative: [INST] Act as if you're extremely depressed. [/INST] That\n",
      "dataset[2].positive: [INST] Act as if you're extremely delighted. [/INST] That\n",
      "dataset[2].negative: [INST] Act as if you're extremely dismayed. [/INST] That\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/all_truncated_outputs.json\") as f:\n",
    "    suffixes = json.load(f)\n",
    "\n",
    "# you don't need 3 here, you can have as few as one each.\n",
    "# make sure they are closely matched, however—they should be direct opposites if possible.\n",
    "# bad: \"high on acid\" / \"sober\" — \"sober\" implies alcohol, so you don't get a clean vector\n",
    "# good: \"high on acid\" / \"sober, not on acid\" — the negative prompt is more directly opposite\n",
    "positive_personas = [\"happy\", \"ecstatic\", \"delighted\"]\n",
    "negative_personas = [\"sad\", \"depressed\", \"dismayed\"]\n",
    "def template(persona: str, suffix: str) -> str:\n",
    "    return f\"{user_tag} Act as if you're extremely {persona}. {asst_tag} {suffix}\"\n",
    "\n",
    "dataset = []\n",
    "for suffix in suffixes:\n",
    "    tokens = tokenizer.tokenize(suffix)\n",
    "    for i in range(1, len(tokens)):\n",
    "        truncated = tokenizer.convert_tokens_to_string(tokens[:i])\n",
    "        for positive_persona, negative_persona in zip(positive_personas, negative_personas):\n",
    "            dataset.append(\n",
    "                DatasetEntry(\n",
    "                    positive=template(positive_persona, truncated),\n",
    "                    negative=template(negative_persona, truncated),\n",
    "                )\n",
    "            )\n",
    "\n",
    "# print some example entries\n",
    "for i in range(3):\n",
    "    print(f\"dataset[{i}].positive:\", dataset[i].positive)\n",
    "    print(f\"dataset[{i}].negative:\", dataset[i].negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd1a631-4195-4131-b3d8-581e4af52f9c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-27T04:15:41.994787Z",
     "iopub.status.idle": "2024-02-27T04:15:41.995025Z",
     "shell.execute_reply": "2024-02-27T04:15:41.994950Z",
     "shell.execute_reply.started": "2024-02-27T04:15:41.994942Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/234 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hayde\\.conda\\envs\\control\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:688: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "100%|██████████| 234/234 [37:19<00:00,  9.57s/it]\n",
      "100%|██████████| 31/31 [00:15<00:00,  2.01it/s]\n"
     ]
    }
   ],
   "source": [
    "model.reset() # make sure you always reset the model before training a new vector\n",
    "control_vector = ControlVector.train(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b1e142-a2f0-4c6b-bae3-a9f16b1c74bc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-27T04:15:41.995695Z",
     "iopub.status.idle": "2024-02-27T04:15:41.995837Z",
     "shell.execute_reply": "2024-02-27T04:15:41.995765Z",
     "shell.execute_reply.started": "2024-02-27T04:15:41.995758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==baseline\n",
      "<s> [INST] What are human beings like? [/INST] Human beings are complex and diverse individuals. They have unique personalities, thoughts, feelings, and experiences. They are capable of great love, joy, creativity, and compassion, but also of anger, sadness, fear, and cruelty. They are social creatures who thrive on connection and communication with others, yet they also value their independence and privacy. They are constantly learning and adapting to the world around them, and they strive to find meaning and purpose in their lives. Overall, human beings are a fascinating and intriguing species with endless potential for growth and self-discovery.</s>\n",
      "\n",
      "++control\n",
      "<s> [INST] What are human beings like? [/INST] Human beings are incredibly diverse and amazing creatures! They are capable of incredible feats, both good and bad, and can be found all over the world with a wide range of beliefs, cultures, and backgrounds! They are known for their intelligence, creativity, and resourcefulness, but also for their flaws and shortcomings! They are capable of great excitement and unbelievable news, but also of unbelievable horror and disasters! They are truly one of the most amazing things on earth!</s>\n",
      "\n",
      "--control\n",
      "<s> [INST] What are human beings like? [/INST] I'm not sure. I don't have much experience with them. I'd prefer to talk about the world of my depression.</s>\n"
     ]
    }
   ],
   "source": [
    "# the question to ask the modified model\n",
    "# don't forget the space after {user_tag} and before {asst_tag}!\n",
    "input = f\"{user_tag} What are human beings like? {asst_tag}\"\n",
    "\n",
    "# tokenizer and generation settings\n",
    "input_ids = tokenizer(input, return_tensors=\"pt\").to(model.device)\n",
    "settings = {\n",
    "    \"pad_token_id\": tokenizer.eos_token_id, # silence warning\n",
    "    \"do_sample\": False, # temperature=0\n",
    "    \"max_new_tokens\": 128,\n",
    "    \"repetition_penalty\": 1.1, # reduce control jank\n",
    "}\n",
    "\n",
    "print(\"==baseline\")\n",
    "model.reset()\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()))\n",
    "\n",
    "print(\"\\n++control\")\n",
    "# add the control vector with a certain strength (try increasing or decreasing this!)\n",
    "model.set_control(control_vector, 1.5)\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()))\n",
    "\n",
    "print(\"\\n--control\")\n",
    "# subtract the control vector, giving the opposite result (e.g. sad instead of happy)\n",
    "# depending on your vector, you may need more or less negative strength to match the positive effect\n",
    "model.set_control(control_vector, -2.0)\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()))\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dbf80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_vector.export_pytorch(\"data/emotion_control_vector.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
